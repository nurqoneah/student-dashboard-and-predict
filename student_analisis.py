# -*- coding: utf-8 -*-
"""student_analisis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AJpE79_lRAqGb0ka0ssUxWpNtPir2q13

# Proyek Akhir: Menyelesaikan Permasalahan Jaya Jaya Institut

Jaya Jaya Institut merupakan salah satu institusi pendidikan perguruan yang telah berdiri sejak tahun 2000. Hingga saat ini ia telah mencetak banyak lulusan dengan reputasi yang sangat baik. Akan tetapi, terdapat banyak juga siswa yang tidak menyelesaikan pendidikannya alias dropout.

Jumlah dropout yang tinggi ini tentunya menjadi salah satu masalah yang besar untuk sebuah institusi pendidikan. Oleh karena itu, Jaya Jaya Institut ingin mendeteksi secepat mungkin siswa yang mungkin akan melakukan dropout sehingga dapat diberi bimbingan khusus.

Proyek ini dilakukan untuk menyelesaikan permasalahan Jaya Jaya Institut  dengan mengidentifikasi berbagai faktor yang mempengaruhi dropout.

- Nama: Nurul Nyi Qoniah
- Email:nurulqoniah313@gmail.com
- Id Dicoding: nurqoneah

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""### Menyiapkan data yang akan digunakan

Dataset yang diganakan pada proyek ini adalah dataset employee yang dapat diakses di [Dataset Student](https://github.com/dicodingacademy/dicoding_dataset/blob/main/students_performance/data.csv)
"""

# Load the dataset from the URL
url = "https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv"
df = pd.read_csv(url, delimiter=";")


df.head()

"""## Data Understanding

Untuk memahami data dari kolom-kolom pada dataset employee, berikut adalah deskripsi singkat dari masing-masing kolom

1. **Marital Status**: Status pernikahan siswa (Single, Married, dll.).
2. **Application Mode**: Metode aplikasi (online, offline, dll.).
3. **Application Order**: Urutan aplikasi (0-9).
4. **Course**: Kursus yang diambil.
5. **Daytime/Evening Attendance**: Waktu kehadiran (Daytime/Evening).
6. **Previous Qualification**: Kualifikasi sebelumnya (SMA, Diploma, dll.).
7. **Previous Qualification Grade**: Nilai dari kualifikasi sebelumnya (0-200).
8. **Nationality**: Kewarganegaraan siswa.
9. **Mother's Qualification**: Kualifikasi pendidikan ibu.
10. **Father's Qualification**: Kualifikasi pendidikan ayah.
11. **Mother's Occupation**: Pekerjaan ibu.
12. **Father's Occupation**: Pekerjaan ayah.
13. **Admission Grade**: Nilai penerimaan (0-200).
14. **Displaced**: Status pengungsi (Yes/No).
15. **Educational Special Needs**: Kebutuhan pendidikan khusus (Yes/No).
16. **Debtor**: Status hutang (Yes/No).
17. **Tuition Fees Up to Date**: Status pembayaran biaya kuliah (Yes/No).
18. **Gender**: Jenis kelamin (Male/Female).
19. **Scholarship Holder**: Status beasiswa (Yes/No).
20. **Age at Enrollment**: Usia pada saat pendaftaran.
21. **International**: Status mahasiswa internasional (Yes/No).
22. **Curricular Units 1st Sem (Credited)**: Unit kurikuler yang diberikan pada semester pertama.
23. **Curricular Units 1st Sem (Enrolled)**: Unit kurikuler yang didaftarkan.
24. **Curricular Units 1st Sem (Evaluations)**: Unit kurikuler yang dievaluasi.
25. **Curricular Units 1st Sem (Approved)**: Unit kurikuler yang disetujui.
26. **Curricular Units 1st Sem (Grade)**: Rata-rata nilai semester pertama.
27. **Curricular Units 1st Sem (Without Evaluations)**: Unit tanpa evaluasi.
28. **Curricular Units 2nd Sem (Credited)**: Unit kurikuler pada semester kedua.
29. **Curricular Units 2nd Sem (Enrolled)**: Unit pada semester kedua yang didaftarkan.
30. **Curricular Units 2nd Sem (Evaluations)**: Evaluasi pada semester kedua.
31. **Curricular Units 2nd Sem (Approved)**: Disetujui pada semester kedua.
32. **Curricular Units 2nd Sem (Grade)**: Rata-rata nilai semester kedua.
33. **Curricular Units 2nd Sem (Without Evaluations)**: Unit tanpa evaluasi semester kedua.
34. **Unemployment Rate**: Tingkat pengangguran.
35. **Inflation Rate**: Tingkat inflasi.
36. **GDP**: Produk Domestik Bruto.
37. **Status**: Status akhir siswa (Lulus, Tidak Lulus, dll.).

Pertama, mari kita lihat 5 baris pertama dari dataframe:
"""

df.head()

"""## Data Preparation / Preprocessing

Selanjutnya, mari kita periksa informasi umum tentang dataframe, seperti jumlah baris dan kolom, tipe data, dan jumlah nilai yang tidak kosong:
"""

df.info()

"""Tidak tedapat missing value dalam data begitu juga dengan tipe data yang sudah tepat

### Encoding Categorical Variables

Variabel kategorikal dikonversi menjadi numerik  pada df
"""

categorical_cols = [
    'Marital_status', 'Application_mode', 'Course', 'Daytime_evening_attendance',
    'Previous_qualification', 'Nacionality', 'Mothers_qualification',
    'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation',
    'Displaced', 'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date',
    'Gender', 'Scholarship_holder', 'International', 'Status'
]

le = LabelEncoder()
for col in categorical_cols:
  df[col] = le.fit_transform(df[col])

df.head()

"""### Scaling Numerical Variables

Fitur baru dibuat dan variabel numerik dinormalisasi pada dataset agar model dapat dilatih dengan data yang seragam
"""

numeric_cols = [
    'Application_order','Application_mode','Course','Mothers_qualification','Fathers_qualification', 'Previous_qualification_grade', 'Admission_grade',
    'Age_at_enrollment', 'Curricular_units_1st_sem_credited', 'Curricular_units_1st_sem_enrolled',
    'Curricular_units_1st_sem_evaluations', 'Curricular_units_1st_sem_approved',
    'Curricular_units_1st_sem_grade', 'Curricular_units_1st_sem_without_evaluations',
    'Curricular_units_2nd_sem_credited', 'Curricular_units_2nd_sem_enrolled',
    'Curricular_units_2nd_sem_evaluations', 'Curricular_units_2nd_sem_approved',
    'Curricular_units_2nd_sem_grade', 'Curricular_units_2nd_sem_without_evaluations'
]

scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

df.head()

"""## Modeling

Kolom Status digunakan sebagai target, sedangkan kolom lainnya digunakan sebagai fitur. Data dibagi menjadi training set dan testing set dengan perbandingan 80:20.
"""

X = df.drop('Status', axis=1)
y = df['Status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Logistic Regression"""

logreg = LogisticRegression(max_iter=1000)
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
logreg_accuracy = accuracy_score(y_test, y_pred_logreg)
print(f"Logistic Regression Accuracy: {logreg_accuracy:.4f}")
print("Logistic Regression Classification Report:\n", classification_report(y_test, y_pred_logreg))

"""### Random Forest"""

random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest.fit(X_train, y_train)
y_pred_rf = random_forest.predict(X_test)
rf_accuracy = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Accuracy: {rf_accuracy:.4f}")
print("Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))

"""### Support Vector Machine (SVM)"""

svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)
svm_accuracy = accuracy_score(y_test, y_pred_svm)
print(f"SVM Accuracy: {svm_accuracy:.4f}")
print("SVM Classification Report:\n", classification_report(y_test, y_pred_svm))

"""## Evaluation

Menggunakan metrik accuracy untuk mengukur performa model pada test set dan laporan klasifikasi untuk lebih memahami rincian prediksi. Untuk mengevaluasi stabilitas model menggunakan cross-validation dengan 5 fold untuk semua model.
"""

# Menggunakan cross-validation untuk lebih akurat membandingkan performa antar model
models = {'Logistic Regression': logreg, 'Random Forest': random_forest, 'SVM': svm}
for model_name, model in models.items():
    scores = cross_val_score(model, X, y, cv=10)
    print(f"{model_name} Cross Validation Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})")

import joblib
joblib.dump(svm, 'svm_model.pkl')
print("SVM model saved as 'svm_model.pkl'")

"""Dari hasil training dapat dilihat bahwa dengan model SVM mendapat Validation Accuracy tertinggi 0.7699"""

# Import library tambahan
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay # Import RocCurveDisplay
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier


# Confusion Matrix untuk Logistic Regression
conf_matrix_logreg = confusion_matrix(y_test, y_pred_logreg)
print("Confusion Matrix for Logistic Regression:\n", conf_matrix_logreg)

# Confusion Matrix untuk Random Forest
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix for Random Forest:\n", conf_matrix_rf)

# Confusion Matrix untuk SVM
conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)
print("Confusion Matrix for SVM:\n", conf_matrix_svm)

# Binarize the output
y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
n_classes = y_test_bin.shape[1]

# ROC Curve untuk ketiga model
plt.figure(figsize=(10, 6))

# Learn to predict each class against the other
classifier = OneVsRestClassifier(
    svm
)  # You can change svm to logreg or random_forest for their respective ROC curves
y_score = classifier.fit(X_train, y_train).decision_function(X_test)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])
    roc_auc[i] = roc_auc_score(y_test_bin[:, i], y_score[:, i])

# Plot of a ROC curve for a specific class
for i in range(n_classes):
    plt.plot(
        fpr[i],
        tpr[i],
        label="ROC curve of class {0} (area = {1:0.2f})".format(i, roc_auc[i]),
    )

plt.plot([0, 1], [0, 1], "k--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver operating characteristic example")
plt.legend(loc="lower right")
plt.show()

"""Random Forest memiliki atribut feature_importances_ yang bisa kita gunakan untuk mengevaluasi seberapa penting setiap fitur dalam menentukan prediksi."""

# Feature Importance dari Random Forest
importances = random_forest.feature_importances_
feature_names = X.columns

# Mengurutkan fitur berdasarkan tingkat kepentingannya
sorted_indices = np.argsort(importances)[::-1]

print("Feature Importance (Random Forest):")
for idx in sorted_indices:
    print(f"{feature_names[idx]}: {importances[idx]:.4f}")

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_names[sorted_indices], importances[sorted_indices])
plt.title('Feature Importance - Random Forest')
plt.show()

"""Logistic Regression memiliki koefisien yang menunjukkan dampak setiap fitur terhadap probabilitas prediksi. Koefisien positif menunjukkan bahwa fitur tersebut meningkatkan peluang Attrition (bernilai "Yes"), sedangkan koefisien negatif menunjukkan sebaliknya."""

# Koefisien dari Logistic Regression
logreg_coef = logreg.coef_[0]
sorted_indices_logreg = np.argsort(abs(logreg_coef))[::-1]

print("Logistic Regression Coefficients:")
for idx in sorted_indices_logreg:
    print(f"{feature_names[idx]}: {logreg_coef[idx]:.4f}")

# Plotting Coefficients
plt.figure(figsize=(10, 6))
plt.barh(feature_names[sorted_indices_logreg], logreg_coef[sorted_indices_logreg])
plt.title('Feature Coefficients - Logistic Regression')
plt.show()

"""### Faktor-Faktor yang Biasanya Mempengaruhi Attrition
Berdasarkan pengalaman dari model seperti ini, beberapa faktor yang umumnya sangat berpengaruh terhadap status student adalah:


*   Tuition_fees_up_to_date
*   Curricular_units_2nd_sem_approved

## Deploy

mencoba menggunakan model untuk prediksi status
"""

# Data yang akan diprediksi
new_data = "1;39;1;9119;1;10;133.1;1;34;37;0;0;128.8;1;0;0;1;1;0;43;0;0;5;0;0;0.0;0;0;5;0;0;0.0;0;7.6;2.6;0.32"

# Memisahkan nilai-nilai dalam string
new_data_list = new_data.split(';')

# Membuat DataFrame dari data baru
# Exclude the last column ('Status') as it's the target variable
new_df = pd.DataFrame([new_data_list], columns=df.columns[:-1])

# Encoding Categorical Variables
for col in categorical_cols:
    if col != 'Status':  # Exclude 'Status' from encoding
        try:
            new_df[col] = le.transform(new_df[col])
        except ValueError as e:
            # Handle unseen labels by assigning a default value
            print(f"Warning: Unseen label in column '{col}'. Assigning default value.")
            new_df[col] = 0  # Assign a default value (e.g., 0)

# Scaling Numerical Variables
new_df[numeric_cols] = scaler.transform(new_df[numeric_cols])

# Melakukan prediksi menggunakan model SVM
y_pred_new_data = svm.predict(new_df)

# Define the mapping of numerical labels to original categories
status_mapping = {
    0: "Dropout",
    1: "Enrolled",
    2: "Graduate"
}

# Map the predicted numerical label to its corresponding category
predicted_status = status_mapping[y_pred_new_data[0]]

print(f"Prediksi Status untuk data baru: {predicted_status}")

"""Save model, label encoder dan standard scaler untuk digunakan di apk streamlit"""

# Save the trained model using joblib
joblib.dump(svm, 'svm_model.pkl')

# Save the label encoder and standard scaler
joblib.dump(le, 'label_encoder.pkl')
joblib.dump(scaler, 'standard_scaler.pkl')